{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from raptor import RetrievalAugmentation\n",
    "from raptor import BaseSummarizationModel, BaseQAModel, BaseEmbeddingModel, RetrievalAugmentationConfig\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"placeholder\" #needed for raptor init, not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Затем загружаем локальный файл .env.local (если он есть)\n",
    "load_dotenv('.env.private', override=True)\n",
    "api_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbedder(BaseEmbeddingModel):\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.api_url = \"https://api.gpt.mws.ru/v1/embeddings\"\n",
    "\n",
    "    @retry(wait=wait_random_exponential(min=20, max=50), stop=stop_after_attempt(200))\n",
    "    def create_embedding(self, text):\n",
    "        headers = {'Authorization': f'Bearer {self.api_key}'}\n",
    "        data = {\n",
    "                \"model\": \"bge-m3\",\n",
    "                \"input\": text\n",
    "            }\n",
    "        try:\n",
    "            response = requests.post(self.api_url, json=data, headers=headers)\n",
    "            return response.json()['data'][0]['embedding']    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSummarizationModel(BaseSummarizationModel):\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.api_url = \"https://api.gpt.mws.ru/v1/chat/completions\"\n",
    "\n",
    "    @retry(wait=wait_random_exponential(min=20, max=50), stop=stop_after_attempt(200))\n",
    "    def summarize(self, context, max_tokens=500):\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "        system_prompt = f\"\"\"Ты ассистент для суммаризации информации\n",
    "Твоя задача - суммаризировать текст, включив в него все необходимые ключевые данные\n",
    "Не отвечай на вопросы в тексте и не добавляй новую информацию\n",
    "Суммаризация не должна превышать {max_tokens} токенов\"\"\"\n",
    "        user_prompt = f\"Текст: {context}\"\n",
    "        data = {\n",
    "            \"model\": 'qwen2.5-72b-instruct',\n",
    "            \"messages\" : [\n",
    "                {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "                {\"role\" : \"use\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": 0,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"n\": 1,\n",
    "            \"frequency_penalty\": 0,\n",
    "            \"presence_penalty\": 0,\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(self.api_url, headers=headers, json=data)\n",
    "            return response.json()['choices'][0]['message']['content']\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(response)\n",
    "            print(response.json())\n",
    "            return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomQAModel(BaseQAModel):\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.api_url = \"https://api.gpt.mws.ru/v1/chat/completions\"\n",
    "        \n",
    "    @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(200))\n",
    "    def answer_question(self, context, question):\n",
    "        # Make the API call with the prompt\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"  # Replace YOUR_API_KEY with your actual API key\n",
    "        }\n",
    "        system_prompt = f\"\"\"Ты ассистент для нахождения ответа на вопрос пользователя\n",
    "Твоя задача - внимательно проанализировать запрос пользователя и найти информацию в предоставленном тексте\n",
    "Постарайся отвечать кратко\"\"\"\n",
    "        user_prompt = f\"\"\"Информация: {context}\n",
    "        \n",
    "Запрос пользователя: {question}\"\"\"\n",
    "        data = {\n",
    "            \"model\": 'deepseek-r1-distill-qwen-32b',\n",
    "            \"messages\" : [\n",
    "                {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "                {\"role\" : \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.1,\n",
    "            \"n\": 1,\n",
    "            \"frequency_penalty\": 0,\n",
    "            \"presence_penalty\": 0,\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.api_url, headers=headers, json=data)\n",
    "            text = response.json()['choices'][0]['message']['content']\n",
    "            think_end = text.index('</think>')\n",
    "            start = think_end + len('</think>')\n",
    "            return text[start:].strip()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_embedder = CustomEmbedder(api_key)\n",
    "custom_qa = CustomQAModel(api_key)\n",
    "custom_summarizer = CustomSummarizationModel(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RetrievalAugmentationConfig(\n",
    "    embedding_model=custom_embedder,\n",
    "    summarization_model=custom_summarizer,\n",
    "    qa_model=custom_qa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raptor = RetrievalAugmentation(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ML_Prekoli/KnowledgeBase.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\\n\\n'.join(df['Поисковой запрос'] + '\\n' + df['Текст'].apply(str.strip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raptor.add_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"RaptorDB.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raptor.save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor = RetrievalAugmentation(config=config, tree=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Как проверить баланс и пакеты по тарифу\"\n",
    "retrived = raptor.retrieve(question, top_k=7)\n",
    "retrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = raptor.answer_question(question, top_k=7)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raptorRag import RaptorRagPipeline\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('.env.private', override=True)\n",
    "api_key = os.getenv('API_KEY')\n",
    "path = 'RaptorDB.pickle'\n",
    "\n",
    "raptorRag = RaptorRagPipeline(api_key, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = raptorRag.pass_prompt(\"Как проверить баланс и пакеты по тарифу\")\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
