{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from typing import List\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from typing import Optional, List, Mapping, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom LLM class to wrap the API call\n",
    "class MTS_Model(LLM):\n",
    "    api_key: str\n",
    "\n",
    "    def _call(self, prompt: str) -> str:\n",
    "        # Make the API call with the prompt\n",
    "        url = \"https://api.gpt.mws.ru/v1/models\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"  # Replace YOUR_API_KEY with your actual API key\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": 'deepseek-r1-distill-qwen-32b',\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 300,\n",
    "            \"top_p\": 1,\n",
    "            \"frequency_penalty\": 0,\n",
    "            \"presence_penalty\": 0,\n",
    "        }\n",
    "        response = requests.post(self.api_url, json=data)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"text\"]\n",
    "        else:\n",
    "            raise Exception(f\"API call failed with status code {response.status_code}\")\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"MTS_Model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTS_Embeddings(Embeddings):\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.api_url = \"https://api.gpt.mws.ru/v1/embeddings\"\n",
    "        \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._get_embedding(text) for text in texts]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self._get_embedding(text)\n",
    "        \n",
    "    def _get_embedding(self, text: str) -> List[float]:\n",
    "        headers = {'Authorization': f'Bearer {self.api_key}'}\n",
    "        data = {'text': text}\n",
    "        response = requests.post(self.api_url, json=data, headers=headers)\n",
    "        return response.json()['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = MTS_Embeddings(api_key)\n",
    "vectorstore = FAISS.load_local(\"path/to/faiss/index\", embeddings=embeddings) #TODO Вот это пока нету\n",
    "retriever = vectorstore.as_retriever()\n",
    "llm = MTS_Model(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Тут просто кусок вайбкода, который надо переделать под задачу\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\n\\nHelpful Answer:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
